{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054cc5ae",
   "metadata": {},
   "source": [
    "# VOLTANDO UMA PASTA PARA TRAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61657c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f21b5",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3390042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.youtube.extract.ytbpy import channel, playlist, utils, video\n",
    "from modules import db_manager\n",
    "from datetime import datetime, timedelta\n",
    "from jinja2 import Template\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import yt_dlp\n",
    "import time\n",
    "import os\n",
    "\n",
    "path_read1          = \"repository\\\\querys\\\\operation\\\\read\\\\game_event.sql\"\n",
    "path_read2          = \"repository\\\\querys\\\\operation\\\\read\\\\game_event_filter.sql\"\n",
    "path_update         = \"repository\\\\querys\\\\operation\\\\insert\\\\game_event.sql\"\n",
    "\n",
    "def ler_json_em_stream(caminho_arquivo):\n",
    "    with open(caminho_arquivo, 'r', encoding='utf-8') as f:\n",
    "        for linha in f:\n",
    "            try:\n",
    "                yield json.loads(linha)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "def wait(seconds=60):\n",
    "    for _ in range(seconds):\n",
    "        time.sleep(1)\n",
    "\n",
    "# lendo tabela de eventos \n",
    "with open(path_read1, \"r\", encoding=\"utf-8\") as file:\n",
    "    query_read1     = file.read()\n",
    "\n",
    "# lendo tabela de eventos \n",
    "with open(path_read2, \"r\", encoding=\"utf-8\") as file:\n",
    "    query_read2     = file.read()\n",
    "\n",
    "# lendo tabela de eventos \n",
    "with open(path_update, \"r\", encoding=\"utf-8\") as file:\n",
    "    query_update1   = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf3434b",
   "metadata": {},
   "source": [
    "# ESCREVENTOS OS EVENTOS NO BANCO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events           = db_manager.read_df(query_read1)\n",
    "\n",
    "# Exemplo de uso:\n",
    "events = []\n",
    "for item in ler_json_em_stream('data\\\\temp\\\\saida.json'):\n",
    "    if item['type'] not in events:\n",
    "        \n",
    "        sql_template = Template(query_update1)\n",
    "        rendered_sql = sql_template.render(\n",
    "            ID_GAME = 1, # ID DO DOTA 2\n",
    "            NAME    = item['type']\n",
    "        ).replace(\"'None'\", \"NULL\").replace(\"None\", \"NULL\")\\\n",
    "        .replace(\"'False'\", \"FALSE\").replace(\"False\", \"FALSE\")\\\n",
    "        .replace(\"'True'\", \"TRUE\").replace(\"True\", \"TRUE\")\n",
    "        \n",
    "        try:\n",
    "            db_manager.execute_raw(rendered_sql)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            db_manager.connection.rollback()\n",
    "            \n",
    "        events.append(item['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c152173",
   "metadata": {},
   "source": [
    "# PARSEANDO OS DADOS E RECORTANDO OS EVENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a01e6b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rattletrap'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_filter    = db_manager.read_df(query_read2)\n",
    "\n",
    "PLAYER_SLOT = 7\n",
    "\n",
    "\"\"\"\n",
    "SO PEGA EVENTOS DO PLAYER, MAS TEM EVENTOS COMO TORRE, CURRIER QUE NÃO E DO PLAYER\n",
    "\"\"\"\n",
    "\n",
    "# Exemplo de uso:\n",
    "structured_data     = {\n",
    "    'time_Start': None,\n",
    "    'steamids': {},\n",
    "    'player_slot': {},\n",
    "    'player_hero': {},\n",
    "    'records': {}\n",
    "}\n",
    "events = df_events_filter[\"name\"].values.tolist()\n",
    "for item in ler_json_em_stream('data\\\\temp\\\\saida.json'):\n",
    "    if item['type'] == 'draft_start':\n",
    "        structured_data['time_Start'] = item['time']\n",
    "        continue\n",
    "    if structured_data['time_Start']: # SE JOGO TIVER TEMPO DIFERENTE DE NONE O GAME FOI INICIADO\n",
    "        if item['type'] == 'steamid':\n",
    "            structured_data['steamids'][item['key']] = item['unit']\n",
    "            continue\n",
    "        elif item['type'] == 'player_slot':\n",
    "            structured_data['player_slot'][item['value']] = item['key']\n",
    "            continue\n",
    "        elif item['type'] == 'interval':\n",
    "            if 'hero_id' in item and 'slot' in item and 'unit' in item:\n",
    "                structured_data['player_hero'][item['slot']] = item['unit'].replace(\"CDOTA_Unit_Hero_\", \"\").replace(\"npc_dota_hero_\", \"\").lower()\n",
    "                continue\n",
    "        elif item['type'] in events:\n",
    "            if PLAYER_SLOT in structured_data['player_hero']:\n",
    "                if structured_data['player_hero'][PLAYER_SLOT] in (json.dumps(item, ensure_ascii=False)).lower():\n",
    "                    if item['time'] not in structured_data[\"records\"]:\n",
    "                        structured_data[\"records\"][item['time']] = []\n",
    "                    time = item['time']\n",
    "                    item = {key:value for key, value in item.items() if key != 'time'}\n",
    "                    structured_data[\"records\"][time].append(item)\n",
    "structured_data['player_hero'][PLAYER_SLOT]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f90e02a",
   "metadata": {},
   "source": [
    "# CRIANDO OS RECORTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e5463fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:06:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnfreitas\\AppData\\Local\\Temp\\ipykernel_3748\\236918563.py:28: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '63.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  cluster_ranges.at[idx, \"time_min\"] = float(row['time_min'] - (10 - row['time_record'])/2)\n",
      "C:\\Users\\johnfreitas\\AppData\\Local\\Temp\\ipykernel_3748\\236918563.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '73.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  cluster_ranges.at[idx, \"time_max\"] = float(row['time_max'] + (10 - row['time_record'])/2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "times = pd.DataFrame({\"times\": sorted(list(structured_data[\"records\"].keys()))})\n",
    "\n",
    "if not times.empty:\n",
    "\n",
    "    # DBSCAN espera dados em formato 2D\n",
    "    X = times['times'].values.reshape(-1, 1)\n",
    "\n",
    "    # eps=10 para diferença máxima de 10s, min_samples=1 para considerar todos os pontos\n",
    "    dbscan = DBSCAN(eps=10, min_samples=1, metric='euclidean')\n",
    "    labels = dbscan.fit_predict(X)\n",
    "\n",
    "    # Adiciona os rótulos dos clusters ao DataFrame\n",
    "    times['cluster'] = labels\n",
    "\n",
    "    # Para cada cluster, encontre o tempo mínimo e máximo\n",
    "    cluster_ranges = (\n",
    "        times.groupby('cluster')['times']\n",
    "        .agg(['min', 'max'])\n",
    "        .reset_index()\n",
    "        .rename(columns={'min': 'time_min', 'max': 'time_max'})\n",
    "    )\n",
    "\n",
    "    cluster_ranges[\"time_record\"] = cluster_ranges[\"time_max\"] - cluster_ranges[\"time_min\"]\n",
    "    for idx, row in cluster_ranges[cluster_ranges[\"time_record\"] < 10].iterrows():\n",
    "        cluster_ranges.at[idx, \"time_min\"] = float(row['time_min'] - (10 - row['time_record'])/2)\n",
    "        cluster_ranges.at[idx, \"time_max\"] = float(row['time_max'] + (10 - row['time_record'])/2)\n",
    "    cluster_ranges[\"time_record\"] = cluster_ranges[\"time_max\"] - cluster_ranges[\"time_min\"]\n",
    "\n",
    "    # Unir intervalos sobrepostos e corrigir tempos mínimos e máximos\n",
    "    def merge_overlapping_intervals(df):\n",
    "        # Ordena pelo tempo mínimo\n",
    "        intervals = df.sort_values('time_min').to_dict('records')\n",
    "        merged = []\n",
    "        for interval in intervals:\n",
    "            if not merged:\n",
    "                merged.append(interval)\n",
    "            else:\n",
    "                last = merged[-1]\n",
    "                # Se houver sobreposição\n",
    "                if interval['time_min'] <= last['time_max']:\n",
    "                    # Atualiza o tempo máximo do último intervalo\n",
    "                    last['time_max'] = max(last['time_max'], interval['time_max'])\n",
    "                    last['time_min'] = min(last['time_min'], interval['time_min'])\n",
    "                    last['time_record'] = last['time_max'] - last['time_min']\n",
    "                    # Opcional: pode manter uma lista de clusters unidos se quiser\n",
    "                else:\n",
    "                    merged.append(interval)\n",
    "        return pd.DataFrame(merged)\n",
    "\n",
    "    cluster_ranges = merge_overlapping_intervals(cluster_ranges)\n",
    "\n",
    "    total_seconds = int(cluster_ranges['time_record'].sum())\n",
    "    print(str(timedelta(seconds=total_seconds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7b5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
